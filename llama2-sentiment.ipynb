{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMCTBPS6qzSqb1tAk1VLVaZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Educational Tutor Chatbot with Sentiment Analysis\n","\n","This project develops an **Educational Tutor Chatbot** that adapts its explanations based on the user's emotional state. Utilizing the Llama 2 model for generating responses and a sentiment analysis model from Hugging Face, the chatbot personalizes its teaching style depending on whether the user is feeling frustrated or satisfied. When detecting **negative sentiment** (e.g., frustration), the bot provides simpler explanations, additional examples, or resources to support learning. For **positive sentiment** responses, the chatbot offers more detailed and challenging explanations to foster deeper understanding. The goal is to create a more engaging and responsive learning environment, helping users stay motivated and succeed in their educational journey."],"metadata":{"id":"qcpdGe-QnUQN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"REIAkQfimqvd"},"outputs":[],"source":["!pip install -q accelerate protobuf sentencepiece torch git+https://github.com/huggingface/transformers huggingface_hub gradio"]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n","from huggingface_hub import login\n","import torch"],"metadata":{"id":"otwpwFDgm1Ql"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hugging Face Authentication\n","login(token=\"hugging_face_token\")"],"metadata":{"id":"PXMuWyoPm4uL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_id = \"NousResearch/Llama-2-7b-chat-hf\"\n","model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"auto\")\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","tokenizer.use_default_system_prompt = False"],"metadata":{"id":"uP7nCTVom53l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["llama_pipeline = pipeline(\n","    \"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\",\n","    max_length=1024,\n",")\n","\n","sentiment_analyzer = pipeline(\"sentiment-analysis\")"],"metadata":{"id":"mNMuIO1inDC8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def answer_question(question):\n","    \"\"\"\n","    Generates an answer to the user's question using Llama 2.\n","\n","    Args:\n","    question (str): The input question from the user.\n","\n","    Returns:\n","    str: The generated answer.\n","    \"\"\"\n","    response = llama_pipeline(question, max_length=150, do_sample=True)[0]['generated_text']\n","    response = response.replace(f\"Answer: {question}\", \"\").strip()\n","    return response\n","\n","def analyze_sentiment(user_input):\n","    \"\"\"\n","    Analyzes the sentiment of the user input.\n","\n","    Args:\n","    user_input (str): The input text from the user.\n","\n","    Returns:\n","    tuple: A tuple containing the sentiment label and score.\n","    \"\"\"\n","    result = sentiment_analyzer(user_input)[0]\n","    label = result['label']\n","    score = result['score']\n","    return label, score\n","\n","def educational_tutor_response(question):\n","    \"\"\"\n","    Generates a sentiment-aware response for the user in an educational context.\n","\n","    Args:\n","    question (str): The input question from the user.\n","\n","    Returns:\n","    str: A sentiment-adjusted response to the question.\n","    \"\"\"\n","    label, score = analyze_sentiment(question)\n","\n","    # Adjust response based on sentiment\n","    if label == \"NEGATIVE\":\n","        sentiment_adjustment = \"It seems you're having some trouble. Let me explain in a simpler way: \"\n","        detailed_help = \"Would you like some additional resources on this topic?\"\n","    elif label == \"POSITIVE\":\n","        sentiment_adjustment = \"Great! I'm glad you're understanding. Here's your answer: \"\n","        detailed_help = \"Feel free to ask more if you're curious!\"\n","    else:\n","        sentiment_adjustment = \"\"\n","        detailed_help = \"\"\n","\n","    # Generate main response\n","    main_response = answer_question(question)\n","\n","    # Provide simpler explanation or encouragement\n","    full_response = f\"{sentiment_adjustment}{main_response}\\n{detailed_help}\"\n","\n","    return full_response"],"metadata":{"id":"STYCmoUtnGPL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gradio Interface\n","interface = gr.Interface(\n","    fn=educational_tutor_response,\n","    inputs=\"text\",\n","    outputs=\"text\",\n","    title=\"Educational Tutor Chatbot with Sentiment Analysis\",\n","    description=\"Ask a question, and the chatbot will analyze your mood, adjust the response, and provide explanations based on your sentiment.\",\n","    examples=[\n","        [\"I'm really confused about how gravity works.\"],\n","        [\"I think I understand quantum physics, but I'm not sure.\"],\n","        [\"Can you explain Pythagoras' theorem?\"],\n","        [\"Why is the sky blue?\"]\n","    ],\n","    theme=\"huggingface\"\n",")\n","\n","# Launch the Gradio Interface\n","interface.launch()"],"metadata":{"id":"B3bmVEucnK_l"},"execution_count":null,"outputs":[]}]}